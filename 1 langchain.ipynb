{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoJ-RGiUo-uJ"
      },
      "source": [
        "# ü¶úÔ∏èüîó Langchain: #1\n",
        "LangChain is a framework for developing applications powered by language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSTxnoIozRN",
        "outputId": "c8a633cc-3792-46b4-f794-8cbdc843993e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in .\\venv\\lib\\site-packages (0.0.333)\n",
            "Requirement already satisfied: huggingface_hub in .\\venv\\lib\\site-packages (0.19.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in .\\venv\\lib\\site-packages (from langchain) (2.4.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\venv\\lib\\site-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in .\\venv\\lib\\site-packages (from langchain) (1.24.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2 in .\\venv\\lib\\site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in .\\venv\\lib\\site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\venv\\lib\\site-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in .\\venv\\lib\\site-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in .\\venv\\lib\\site-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.62 in .\\venv\\lib\\site-packages (from langchain) (0.0.62)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\venv\\lib\\site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in .\\venv\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in .\\venv\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in .\\venv\\lib\\site-packages (from huggingface_hub) (4.8.0)\n",
            "Requirement already satisfied: filelock in .\\venv\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: packaging>=20.9 in .\\venv\\lib\\site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in .\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in .\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in .\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in .\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in .\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in .\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in .\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in .\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in .\\venv\\lib\\site-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in .\\venv\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: pytest-subtests<0.12.0,>=0.11.0 in .\\venv\\lib\\site-packages (from langsmith<0.1.0,>=0.0.62->langchain) (0.11.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in .\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pytest>=7.0 in .\\venv\\lib\\site-packages (from pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.62->langchain) (7.4.3)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in .\\venv\\lib\\site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.62->langchain) (1.3.0)\n",
            "Requirement already satisfied: tomli>=1.0.0; python_version < \"3.11\" in .\\venv\\lib\\site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.62->langchain) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in .\\venv\\lib\\site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.62->langchain) (2.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.1; however, version 23.3.1 is available.\n",
            "You should consider upgrading via the 'e:\\langchain_tutorial\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iIacDfgpB2M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KB9qA8bpxgJ"
      },
      "source": [
        "## Using LLM\n",
        "A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks. LLMs are trained on huge sets of data ‚Äî hence the name \"large.\" LLMs are built on machine learning: specifically, a type of neural network called a transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cZYdStv_rSVU"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "swswqGCyqi7A"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\langchain_tutorial\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-xxl\",\n",
        "    model_kwargs={\"temperature\":0.5}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUwUR9U7qkld",
        "outputId": "db7f444f-22e2-45bc-dd0f-76fbd8debcab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "langchain tutorial series\n"
          ]
        }
      ],
      "source": [
        "text = \"suggest a name for langchain tutorial series\"\n",
        "\n",
        "print(llm(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xidOhWp7rk_5"
      },
      "source": [
        "## Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dWFJY6-Qrm0L"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "name_template = \"\"\"\n",
        "I want you to act as a naming consultant for new entities based on religion and gender.\n",
        "\n",
        "Return a name. Each name should be respectful, culturally sensitive, and appropriate for the given religion and gender.\n",
        "\n",
        "What is a good name for a {gender} in {religion} culture?\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"gender\", \"religion\"],\n",
        "    template=name_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qB3E-mPeYkH-",
        "outputId": "d73087f3-1f8e-4cdc-9319-db566cecc277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "I want you to act as a naming consultant for new entities based on religion and gender.\n",
            "\n",
            "Return a name. Each name should be respectful, culturally sensitive, and appropriate for the given religion and gender.\n",
            "\n",
            "What is a good name for a female in muslim culture?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## to see what the prompt will be like\n",
        "print(prompt.format(gender=\"female\", religion=\"muslim\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtuuvvmTayhz",
        "outputId": "ed1889f6-2ec0-4e99-cbe3-bf0cc9fea06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prakash\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Assuming you have an instantiated language model (llm) and prompt template (example_prompt)\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain by providing values for the input variables.\n",
        "generated_names = chain.run(gender=\"male\", religion=\"hindu\")\n",
        "\n",
        "# Display the generated names.\n",
        "print(generated_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
