{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶úÔ∏èüîó Langchain: #2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain import PromptTemplate\n",
    "import os\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'Your_token'\n",
    "# llm model\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-xxl\",\n",
    "    model_kwargs={\"temperature\":0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompt\n",
    "The ``PromptTemplate`` class is designed to handle a single prompt template with placeholders for variables.\n",
    "\n",
    "The ``FewShotPromptTemplate`` class, on the other hand, allows you to provide a list of examples, each consisting of input values and their corresponding outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: Water is solid at room temperature\n",
      "Answer: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the template to format the true/false examples.\n",
    "template = \"\"\"Statement: {statement}\n",
    "Answer: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# Create the PromptTemplate for true/false examples.\n",
    "true_false_prompt = PromptTemplate(\n",
    "    input_variables=[\"statement\", \"answer\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "print(true_false_prompt.format(statement=\"Water is solid at room temperature\",\n",
    "                               answer=\"False\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer each statement as True or False\n",
      "\n",
      "Statement: Elephants can fly\n",
      "Answer: False\n",
      "\n",
      "Statement: Water boils at 100 degrees Celsius\n",
      "Answer: True\n",
      "\n",
      "Statement: Fish can not fly\n",
      "Answer: True\n",
      "\n",
      "Statement: Water is solid at room temperature\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# Create a list of true/false examples.\n",
    "true_false_examples = [\n",
    "    {\"statement\": \"Elephants can fly\", \"answer\": \"False\"},\n",
    "    {\"statement\": \"Water boils at 100 degrees Celsius\", \"answer\": \"True\"},\n",
    "    {\"statement\": \"Fish can not fly\", \"answer\": \"True\"},\n",
    "]\n",
    "\n",
    "# Create the FewShotPromptTemplate for true/false examples.\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=true_false_examples,\n",
    "    example_prompt=true_false_prompt,\n",
    "    prefix=\"Answer each statement as True or False\\n\",\n",
    "    suffix=\"Statement: {input}\\nAnswer:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "# Use the true/false few-shot prompt template.\n",
    "print(prompt.format(input=\"Water is solid at room temperature\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Assuming you have an instantiated language model (llm) and prompt template (example_prompt)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain by providing values for the input variables.\n",
    "generated_names = chain.run(input=\"Bird can fly\")\n",
    "\n",
    "# Display the generated names.\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save prompt\n",
    "prompt.save(\"few_shot_temp.json\")\n",
    "\n",
    "#Load prompt\n",
    "from langchain.prompts import load_prompt\n",
    "loaded_prompt = load_prompt(\"few_shot_temp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer each statement as True or False\n",
      "\n",
      "Statement: Elephants can fly\n",
      "Answer: False\n",
      "\n",
      "Statement: Water boils at 100 degrees Celsius\n",
      "Answer: True\n",
      "\n",
      "Statement: Fish can not fly\n",
      "Answer: True\n",
      "\n",
      "Statement: Birds can fly\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(loaded_prompt.format(input=\"Birds can fly\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
